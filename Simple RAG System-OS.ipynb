{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "68e38f45-6ab2-41db-9bae-8c316796cdd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World!\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello World!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d934145-6c52-4725-8b01-a8c0e8905ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pdf_data:  Maruti Mohit Rayalacheruvu \n",
      "(857) 313-2407 | rayalacheruvu.m@northeastern.edu | https://linkedin.com/in/marutimohitr \n",
      " \n",
      "EDUCATION \n",
      "Master of Science in Information Systems, Northeastern University​\n",
      "December 2024 \n",
      " \n",
      "Bachelor of Engineering in Computer Science, Visvesvaraya Technological University​\n",
      "July 2021 \n",
      " \n",
      "TECHNICAL SKILLS \n",
      "Programming Languages: Python, Java, C#, C,  C++ \n",
      "Data Science & ML: Scikit-learn, Statistical Analysis, Data Visualization (Matplotlib, Seaborn), Classification Models, \n"
     ]
    }
   ],
   "source": [
    "import fitz\n",
    "import glob\n",
    "\n",
    "def load_all_pdfs_in_directory(directory=\"./content/\"):\n",
    "  combined_text = \"\"\n",
    "  pdf_paths = glob.glob(f\"{directory}/*.pdf\")\n",
    "\n",
    "  for file_path in pdf_paths:\n",
    "    with fitz.open(file_path) as pdf:\n",
    "      for page in pdf:\n",
    "        combined_text += page.get_text()\n",
    "\n",
    "  return combined_text\n",
    "\n",
    "pdf_data = load_all_pdfs_in_directory()\n",
    "print(\"Pdf_data: \", pdf_data[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d20ec44-aa0f-427c-8628-4ce6dc1e58e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13088"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pdf_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a0fbd33-9d64-4076-b5d5-ebbee28ce9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents:  15\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1200,\n",
    "    chunk_overlap=300\n",
    ")\n",
    "\n",
    "documents = text_splitter.split_text(pdf_data)\n",
    "print(\"Number of documents: \", len(documents))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1fefec4b-53e4-40c0-94b9-c5aaec6ae387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Maruti Mohit Rayalacheruvu \\n(857) 313-2407 | rayalacheruvu.m@northeastern.edu | https://linkedin.com/in/marutimohitr \\n \\nEDUCATION \\nMaster of Science in Information Systems, Northeastern University\\u200b\\nDecember 2024 \\n \\nBachelor of Engineering in Computer Science, Visvesvaraya Technological University\\u200b\\nJuly 2021 \\n \\nTECHNICAL SKILLS \\nProgramming Languages: Python, Java, C#, C,  C++ \\nData Science & ML: Scikit-learn, Statistical Analysis, Data Visualization (Matplotlib, Seaborn), Classification Models, \\nFeature Engineering, Pandas, NumPy, Model Optimization, Jupyter, Predictive Modeling \\nTechnologies: SQL (PostgreSQL), AWS, JavaScript, TypeScript, React, Node.js, Express, MongoDB, Docker, CI/CD \\nFrameworks: Data Structures & Algorithms, Microservices Architecture, .NET Core, Git, Linux, Unit Testing, Postman \\n \\nWORK EXPERIENCE \\nAssociate Software Engineer, Conga\\u200b\\n\\u200b\\nJuly 2021 – August 2022 \\n●\\u200b Architected cloud-native microservices with C#, .NET Core, and AWS to process documents across cloud storage \\nproviders, implementing data pipelines for real-time analytics and processing \\n●\\u200b Optimized event-driven communication by configuring Amazon SQS and SNS and monitoring Grafana dashboards,'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "08ce4dc0-a9f9-40a8-90ed-b0df8da18078",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=\"llama3.2\")\n",
    "\n",
    "embedded_documents = embeddings.embed_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e7f4fcfd-7dc7-45b1-a8b8-fdc0c4d86b9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding for the first document\n",
      "Component 1: 0.008273192\n",
      "Component 2: -0.0009663236\n",
      "Component 3: -0.013073141\n",
      "Component 4: 0.008556816\n",
      "Component 5: -0.0065383804\n",
      "Component 6: 0.013164695\n"
     ]
    }
   ],
   "source": [
    "print(\"Embedding for the first document\")\n",
    "for i, value in enumerate(embedded_documents[0]):\n",
    "  print(f\"Component {i+1}: {value}\")\n",
    "  if i >= 5:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c5a5a6ce-4017-4746-92ae-900089a8b11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorstore created and stored successfully\n"
     ]
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "import chromadb\n",
    "\n",
    "client = chromadb.Client()\n",
    "\n",
    "chroma_db_directory = \"./chroma_index\"\n",
    "\n",
    "vectorstore = Chroma.from_texts(texts=documents, embedding=embeddings, client=client, persist_directory=chroma_db_directory)\n",
    "\n",
    "print(\"Vectorstore created and stored successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2dd34ab6-53ca-4235-a2ff-a564d1e8365e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents indexed: 15\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of documents indexed: {len(documents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2b52e4da-9102-4d47-b8b2-c954ff9738a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f289554b-22dd-4ffc-8e8b-baf9ff825d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print(docs):\n",
    "  print(\n",
    "      f\"\\n{'-' * 100}\\n\".join(\n",
    "          [f\"Document {i+1}:\\n\\n\"+ d.page_content for i,d in enumerate(docs)]\n",
    "      )\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fabccb8e-94d4-4863-a442-bdb9a7b6611a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for query 1:\n",
      "Document 1:\n",
      "\n",
      "SKILLS\n",
      "Frameworks: TensorFlow, TernsorFlow Serving, PyTorch, PySpark\n",
      "Models: DBSCAN, BERT, R-CNN, Multi-Linear Regression, Polynomial Regression, Random Forest, SVM, SARSA\n",
      "Cloud: Amazon Web Services, Google Cloud Platform.\n",
      "EXPERIENCE\n",
      "Sopra Steria\n",
      "Jan 2021 - Dec 2023\n",
      "Data Scientist\n",
      "• Gathered historical data on user roles and access patterns. Applied Singular Value Decomposition to reduce\n",
      "the dimensionality of the user-permission matrix. The DBSCAN clustering algorithm was used to analyze\n",
      "user roles, attributes, and group relationships, ensuring accurate and scalable access control.\n",
      "Machine Learning Engineer\n",
      "• Built an NLP model using BERT to analyze detailed descriptions of ServiceNow tickets and automatically\n",
      "classify them into resolution categories. The model was trained on historical ticket data to improve assign-\n",
      "ment accuracy and reduce manual efforts.\n",
      "• Developed a RAG model using Hugging Face Transformers, integrating organizational password policies to\n",
      "deliver targeted security recommendations. Enhanced policy compliance through personalized guidance\n",
      "supported by company-speciﬁc documentation.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "ment accuracy and reduce manual efforts.\n",
      "• Developed a RAG model using Hugging Face Transformers, integrating organizational password policies to\n",
      "deliver targeted security recommendations. Enhanced policy compliance through personalized guidance\n",
      "supported by company-speciﬁc documentation.\n",
      "• Engaged closely with Product Owners to gather and reﬁne application requirements, ensuring they aligned\n",
      "with business goals. Facilitated seamless collaboration among Product Owners, Developers, and Customers\n",
      "to quickly resolve technical challenges.\n",
      "Boston University\n",
      "September 2024 - May 2025\n",
      "Teaching Assistant - Big Data Analytics\n",
      "• Assisted students in deploying PySpark code on GCP and AWS. Troubleshooting cloud issues, teaching best\n",
      "practices for efﬁcient big data processing, and guided code optimization to prevent cluster node crashes.\n",
      "PROJECTS\n",
      "Object Detection on Google’s Open Images Dataset:\n",
      "• Using the distributed computing capabilities of PySpark to preprocess Google’s Open Images Dataset (1M+\n",
      "images) and implemented R-CNN and SSD object detection models using PyTorch on GCP’s distributed in-\n",
      "frastructure.\n",
      "Game of Tigers and Goats:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "Maruti Mohit Rayalacheruvu \n",
      "(857) 313-2407 | rayalacheruvu.m@northeastern.edu | https://linkedin.com/in/marutimohitr \n",
      " \n",
      "EDUCATION \n",
      "Master of Science in Information Systems, Northeastern University​\n",
      "December 2024 \n",
      " \n",
      "Bachelor of Engineering in Computer Science, Visvesvaraya Technological University​\n",
      "July 2021 \n",
      " \n",
      "TECHNICAL SKILLS \n",
      "Programming Languages: Python, Java, C#, C,  C++ \n",
      "Data Science & ML: Scikit-learn, Statistical Analysis, Data Visualization (Matplotlib, Seaborn), Classification Models, \n",
      "Feature Engineering, Pandas, NumPy, Model Optimization, Jupyter, Predictive Modeling \n",
      "Technologies: SQL (PostgreSQL), AWS, JavaScript, TypeScript, React, Node.js, Express, MongoDB, Docker, CI/CD \n",
      "Frameworks: Data Structures & Algorithms, Microservices Architecture, .NET Core, Git, Linux, Unit Testing, Postman \n",
      " \n",
      "WORK EXPERIENCE \n",
      "Associate Software Engineer, Conga​\n",
      "​\n",
      "July 2021 – August 2022 \n",
      "●​ Architected cloud-native microservices with C#, .NET Core, and AWS to process documents across cloud storage \n",
      "providers, implementing data pipelines for real-time analytics and processing \n",
      "●​ Optimized event-driven communication by configuring Amazon SQS and SNS and monitoring Grafana dashboards,\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4:\n",
      "\n",
      "Pega PRPC, and PostgreSQL, driving significant revenue growth for UnitedHealth Group. \n",
      "• \n",
      "Architected and engineered downstream RESTful APIs with Java Spring Boot, enabling seamless integration between insurance \n",
      "plans, field agents, and the Pega system, while integrating Kafka for real-time data streaming. \n",
      "• \n",
      "Developed a custom Java security event logging solution using Log4J, safeguarding customer PHI/PII and reducing data breach \n",
      "risks by 85%, ensuring compliance with industry security standards. \n",
      "• \n",
      "Led the application upgrade project during COVID-19, optimizing case management processes and integrating Adobe Sign and \n",
      "SMS APIs, boosting operational resilience and ensuring uninterrupted business continuity. \n",
      " \n",
      "Programmer Analyst, Cognizant                                                                                                                                                  Jun 2019 - Jul 2021 \n",
      "• \n",
      "Revamped the architecture of an Equity and Debt investment processing application for World Bank Group, improving case \n",
      "processing lifecycle and disbursement time by 30% through advanced system design. \n",
      "•\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 5:\n",
      "\n",
      "98% while maintaining 99% of variance; created interactive Plotly visualizations for gene expression patterns and \n",
      "comparative model performance analysis \n",
      " \n",
      "Music Streaming Database Management System​\n",
      "August 2023 \n",
      "●​ Architected a comprehensive Oracle database system for a music streaming platform, designing 9 interconnected \n",
      "tables with referential integrity and implementing role-based access control (RBAC) for user and artist data \n",
      "management \n",
      "●​ Created 5 PL/SQL packages with 25+ stored procedures for playlist management, song ratings, and artist-album \n",
      "relationships, ensuring data consistency through transaction management and error handling \n",
      "●​ Enhanced system analytics through 9 optimized database views and implementing 5 automated triggers, enabling \n",
      "real-time insights into user preferences while maintaining data quality through rating constraints \n",
      " \n",
      "News Classification System​\n",
      "April 2023 \n",
      "●​ Developed a machine learning-based news classification system using Python, scikit-learn, and NLP techniques to \n",
      "automatically categorize news articles for content accuracy \n",
      "●​ Implemented an ensemble learning solution combining Random Forest, SVM, and BERT classifiers, achieving over\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 6:\n",
      "\n",
      "Object Detection on Google’s Open Images Dataset:\n",
      "• Using the distributed computing capabilities of PySpark to preprocess Google’s Open Images Dataset (1M+\n",
      "images) and implemented R-CNN and SSD object detection models using PyTorch on GCP’s distributed in-\n",
      "frastructure.\n",
      "Game of Tigers and Goats:\n",
      "• Developed and implemented a game that features two players (Goat and Tiger). Designed and trained SARSA\n",
      "reinforcement learning agents to optimize player strategies, improving model performance through iterative\n",
      "game simulations.\n",
      "Parkinson’s Disease Regression Analysis\n",
      "• Statistical tests (ANOVA, F-Test) and feature selection techniques were performed to develop regression\n",
      "models to predict Total UPDRS scores in Parkinson’s patients, utilizing voice-related features. Built and op-\n",
      "timized multiple models, including Multi-Linear and Polynomial Regression, to improve prediction accuracy.\n",
      "Online Shoppers Purchasing Intention\n",
      "• Built predictive models using classiﬁers like Random Forest and SVM to analyze online shopper behavior and\n",
      "purchase intentions, addressing class imbalance through under-sampling and over-sampling techniques.\n",
      "EDUCATION\n",
      "Boston University\n",
      "Expected May 2025\n",
      "\n",
      "Results for query 2:\n",
      "Document 1:\n",
      "\n",
      "SKILLS\n",
      "Frameworks: TensorFlow, TernsorFlow Serving, PyTorch, PySpark\n",
      "Models: DBSCAN, BERT, R-CNN, Multi-Linear Regression, Polynomial Regression, Random Forest, SVM, SARSA\n",
      "Cloud: Amazon Web Services, Google Cloud Platform.\n",
      "EXPERIENCE\n",
      "Sopra Steria\n",
      "Jan 2021 - Dec 2023\n",
      "Data Scientist\n",
      "• Gathered historical data on user roles and access patterns. Applied Singular Value Decomposition to reduce\n",
      "the dimensionality of the user-permission matrix. The DBSCAN clustering algorithm was used to analyze\n",
      "user roles, attributes, and group relationships, ensuring accurate and scalable access control.\n",
      "Machine Learning Engineer\n",
      "• Built an NLP model using BERT to analyze detailed descriptions of ServiceNow tickets and automatically\n",
      "classify them into resolution categories. The model was trained on historical ticket data to improve assign-\n",
      "ment accuracy and reduce manual efforts.\n",
      "• Developed a RAG model using Hugging Face Transformers, integrating organizational password policies to\n",
      "deliver targeted security recommendations. Enhanced policy compliance through personalized guidance\n",
      "supported by company-speciﬁc documentation.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "Maruti Mohit Rayalacheruvu \n",
      "(857) 313-2407 | rayalacheruvu.m@northeastern.edu | https://linkedin.com/in/marutimohitr \n",
      " \n",
      "EDUCATION \n",
      "Master of Science in Information Systems, Northeastern University​\n",
      "December 2024 \n",
      " \n",
      "Bachelor of Engineering in Computer Science, Visvesvaraya Technological University​\n",
      "July 2021 \n",
      " \n",
      "TECHNICAL SKILLS \n",
      "Programming Languages: Python, Java, C#, C,  C++ \n",
      "Data Science & ML: Scikit-learn, Statistical Analysis, Data Visualization (Matplotlib, Seaborn), Classification Models, \n",
      "Feature Engineering, Pandas, NumPy, Model Optimization, Jupyter, Predictive Modeling \n",
      "Technologies: SQL (PostgreSQL), AWS, JavaScript, TypeScript, React, Node.js, Express, MongoDB, Docker, CI/CD \n",
      "Frameworks: Data Structures & Algorithms, Microservices Architecture, .NET Core, Git, Linux, Unit Testing, Postman \n",
      " \n",
      "WORK EXPERIENCE \n",
      "Associate Software Engineer, Conga​\n",
      "​\n",
      "July 2021 – August 2022 \n",
      "●​ Architected cloud-native microservices with C#, .NET Core, and AWS to process documents across cloud storage \n",
      "providers, implementing data pipelines for real-time analytics and processing \n",
      "●​ Optimized event-driven communication by configuring Amazon SQS and SNS and monitoring Grafana dashboards,\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "ment accuracy and reduce manual efforts.\n",
      "• Developed a RAG model using Hugging Face Transformers, integrating organizational password policies to\n",
      "deliver targeted security recommendations. Enhanced policy compliance through personalized guidance\n",
      "supported by company-speciﬁc documentation.\n",
      "• Engaged closely with Product Owners to gather and reﬁne application requirements, ensuring they aligned\n",
      "with business goals. Facilitated seamless collaboration among Product Owners, Developers, and Customers\n",
      "to quickly resolve technical challenges.\n",
      "Boston University\n",
      "September 2024 - May 2025\n",
      "Teaching Assistant - Big Data Analytics\n",
      "• Assisted students in deploying PySpark code on GCP and AWS. Troubleshooting cloud issues, teaching best\n",
      "practices for efﬁcient big data processing, and guided code optimization to prevent cluster node crashes.\n",
      "PROJECTS\n",
      "Object Detection on Google’s Open Images Dataset:\n",
      "• Using the distributed computing capabilities of PySpark to preprocess Google’s Open Images Dataset (1M+\n",
      "images) and implemented R-CNN and SSD object detection models using PyTorch on GCP’s distributed in-\n",
      "frastructure.\n",
      "Game of Tigers and Goats:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4:\n",
      "\n",
      "Online Shoppers Purchasing Intention\n",
      "• Built predictive models using classiﬁers like Random Forest and SVM to analyze online shopper behavior and\n",
      "purchase intentions, addressing class imbalance through under-sampling and over-sampling techniques.\n",
      "EDUCATION\n",
      "Boston University\n",
      "Expected May 2025\n",
      "Master of Science in Applied Data Analytics\n",
      "Relevant Coursework: Data Science, Advanced Machine Learning, Big Data Analytics - PySpark, Generative AI.\n",
      "Saimahith Chigurupati \n",
      "Boston, MA | 857-693-9706 | mahithchigurupati@gmail.com | LinkedIn | GitHub \n",
      "Software Engineer with 5+ Years of Expertise in Designing Scalable Systems and Delivering Innovative Solutions  \n",
      "SKILLS \n",
      "Programming Languages  \n",
      "Python, Java, C, JavaScript \n",
      "Web Technologies \n",
      " \n",
      "Spring Boot, FastAPI, Node.js, React.js, Next.js, Tailwind, REST API, GraphQL, Django REST \n",
      "DevOps and Cloud \n",
      " \n",
      "AWS, GCP, Linux, Git, Docker, Kubernetes, Jenkins, CI/CD, Terraform, Packer, Apache Kafka \n",
      "Databases & Tools \n",
      " \n",
      "MySQL, PostgreSQL, NoSQL, MongoDB, Redis, Azure SQL, Hibernate, RabbitMQ, SwiftUI \n",
      "Certifications \n",
      " \n",
      "                AWS Certified Solutions Architect, Pega Certified Senior System Architect \n",
      " \n",
      "WORK EXPERIENCE\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 5:\n",
      "\n",
      "Object Detection on Google’s Open Images Dataset:\n",
      "• Using the distributed computing capabilities of PySpark to preprocess Google’s Open Images Dataset (1M+\n",
      "images) and implemented R-CNN and SSD object detection models using PyTorch on GCP’s distributed in-\n",
      "frastructure.\n",
      "Game of Tigers and Goats:\n",
      "• Developed and implemented a game that features two players (Goat and Tiger). Designed and trained SARSA\n",
      "reinforcement learning agents to optimize player strategies, improving model performance through iterative\n",
      "game simulations.\n",
      "Parkinson’s Disease Regression Analysis\n",
      "• Statistical tests (ANOVA, F-Test) and feature selection techniques were performed to develop regression\n",
      "models to predict Total UPDRS scores in Parkinson’s patients, utilizing voice-related features. Built and op-\n",
      "timized multiple models, including Multi-Linear and Polynomial Regression, to improve prediction accuracy.\n",
      "Online Shoppers Purchasing Intention\n",
      "• Built predictive models using classiﬁers like Random Forest and SVM to analyze online shopper behavior and\n",
      "purchase intentions, addressing class imbalance through under-sampling and over-sampling techniques.\n",
      "EDUCATION\n",
      "Boston University\n",
      "Expected May 2025\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 6:\n",
      "\n",
      "●​ Developed a machine learning-based news classification system using Python, scikit-learn, and NLP techniques to \n",
      "automatically categorize news articles for content accuracy \n",
      "●​ Implemented an ensemble learning solution combining Random Forest, SVM, and BERT classifiers, achieving over \n",
      "95% accuracy rate \n",
      "●​ Improved model performance through feature engineering and hyperparameter tuning, reducing false positives using \n",
      "weighted voting mechanisms across classifiers \n",
      " \n",
      "LEADERSHIP & ACHIEVEMENTS \n",
      "●​ Recognized for exceptional work on integrating S3 and SFTP with microservices for efficient document delivery \n",
      "●​ Led knowledge-sharing sessions for 10+ engineers on AWS, data visualization frameworks, and machine learning \n",
      "pipelines, enhancing team productivity and project efficiency \n",
      "Deepak Swaminathan\n",
      "LinkedIn | R 23.deepak.s@gmail.com | Ó (857) 506-5534\n",
      "SKILLS\n",
      "Frameworks: TensorFlow, TernsorFlow Serving, PyTorch, PySpark\n",
      "Models: DBSCAN, BERT, R-CNN, Multi-Linear Regression, Polynomial Regression, Random Forest, SVM, SARSA\n",
      "Cloud: Amazon Web Services, Google Cloud Platform.\n",
      "EXPERIENCE\n",
      "Sopra Steria\n",
      "Jan 2021 - Dec 2023\n",
      "Data Scientist\n"
     ]
    }
   ],
   "source": [
    "# Define your queries\n",
    "query_1 = \"who does the document discuss about?\"\n",
    "query_2 = \"what are his achievements?\"\n",
    "\n",
    "# Retrieve relevant documents for the queries\n",
    "docs_1 = retriever.invoke(query_1)\n",
    "docs_2 = retriever.invoke(query_2)\n",
    "\n",
    "# Pretty print the results\n",
    "print(\"Results for query 1:\")\n",
    "pretty_print(docs_1)\n",
    "\n",
    "print(\"\\nResults for query 2:\")\n",
    "pretty_print(docs_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "76631f4c-9f17-40e8-b1be-f1c33d646c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for query 1:\n",
      "Document 1:\n",
      "\n",
      "Object Detection on Google’s Open Images Dataset:\n",
      "• Using the distributed computing capabilities of PySpark to preprocess Google’s Open Images Dataset (1M+\n",
      "images) and implemented R-CNN and SSD object detection models using PyTorch on GCP’s distributed in-\n",
      "frastructure.\n",
      "Game of Tigers and Goats:\n",
      "• Developed and implemented a game that features two players (Goat and Tiger). Designed and trained SARSA\n",
      "reinforcement learning agents to optimize player strategies, improving model performance through iterative\n",
      "game simulations.\n",
      "Parkinson’s Disease Regression Analysis\n",
      "• Statistical tests (ANOVA, F-Test) and feature selection techniques were performed to develop regression\n",
      "models to predict Total UPDRS scores in Parkinson’s patients, utilizing voice-related features. Built and op-\n",
      "timized multiple models, including Multi-Linear and Polynomial Regression, to improve prediction accuracy.\n",
      "Online Shoppers Purchasing Intention\n",
      "• Built predictive models using classiﬁers like Random Forest and SVM to analyze online shopper behavior and\n",
      "purchase intentions, addressing class imbalance through under-sampling and over-sampling techniques.\n",
      "EDUCATION\n",
      "Boston University\n",
      "Expected May 2025\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "Maruti Mohit Rayalacheruvu \n",
      "(857) 313-2407 | rayalacheruvu.m@northeastern.edu | https://linkedin.com/in/marutimohitr \n",
      " \n",
      "EDUCATION \n",
      "Master of Science in Information Systems, Northeastern University​\n",
      "December 2024 \n",
      " \n",
      "Bachelor of Engineering in Computer Science, Visvesvaraya Technological University​\n",
      "July 2021 \n",
      " \n",
      "TECHNICAL SKILLS \n",
      "Programming Languages: Python, Java, C#, C,  C++ \n",
      "Data Science & ML: Scikit-learn, Statistical Analysis, Data Visualization (Matplotlib, Seaborn), Classification Models, \n",
      "Feature Engineering, Pandas, NumPy, Model Optimization, Jupyter, Predictive Modeling \n",
      "Technologies: SQL (PostgreSQL), AWS, JavaScript, TypeScript, React, Node.js, Express, MongoDB, Docker, CI/CD \n",
      "Frameworks: Data Structures & Algorithms, Microservices Architecture, .NET Core, Git, Linux, Unit Testing, Postman \n",
      " \n",
      "WORK EXPERIENCE \n",
      "Associate Software Engineer, Conga​\n",
      "​\n",
      "July 2021 – August 2022 \n",
      "●​ Architected cloud-native microservices with C#, .NET Core, and AWS to process documents across cloud storage \n",
      "providers, implementing data pipelines for real-time analytics and processing \n",
      "●​ Optimized event-driven communication by configuring Amazon SQS and SNS and monitoring Grafana dashboards,\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "Pega PRPC, and PostgreSQL, driving significant revenue growth for UnitedHealth Group. \n",
      "• \n",
      "Architected and engineered downstream RESTful APIs with Java Spring Boot, enabling seamless integration between insurance \n",
      "plans, field agents, and the Pega system, while integrating Kafka for real-time data streaming. \n",
      "• \n",
      "Developed a custom Java security event logging solution using Log4J, safeguarding customer PHI/PII and reducing data breach \n",
      "risks by 85%, ensuring compliance with industry security standards. \n",
      "• \n",
      "Led the application upgrade project during COVID-19, optimizing case management processes and integrating Adobe Sign and \n",
      "SMS APIs, boosting operational resilience and ensuring uninterrupted business continuity. \n",
      " \n",
      "Programmer Analyst, Cognizant                                                                                                                                                  Jun 2019 - Jul 2021 \n",
      "• \n",
      "Revamped the architecture of an Equity and Debt investment processing application for World Bank Group, improving case \n",
      "processing lifecycle and disbursement time by 30% through advanced system design. \n",
      "•\n",
      "\n",
      "Results for query 2:\n",
      "Document 1:\n",
      "\n",
      "●​ Developed a machine learning-based news classification system using Python, scikit-learn, and NLP techniques to \n",
      "automatically categorize news articles for content accuracy \n",
      "●​ Implemented an ensemble learning solution combining Random Forest, SVM, and BERT classifiers, achieving over \n",
      "95% accuracy rate \n",
      "●​ Improved model performance through feature engineering and hyperparameter tuning, reducing false positives using \n",
      "weighted voting mechanisms across classifiers \n",
      " \n",
      "LEADERSHIP & ACHIEVEMENTS \n",
      "●​ Recognized for exceptional work on integrating S3 and SFTP with microservices for efficient document delivery \n",
      "●​ Led knowledge-sharing sessions for 10+ engineers on AWS, data visualization frameworks, and machine learning \n",
      "pipelines, enhancing team productivity and project efficiency \n",
      "Deepak Swaminathan\n",
      "LinkedIn | R 23.deepak.s@gmail.com | Ó (857) 506-5534\n",
      "SKILLS\n",
      "Frameworks: TensorFlow, TernsorFlow Serving, PyTorch, PySpark\n",
      "Models: DBSCAN, BERT, R-CNN, Multi-Linear Regression, Polynomial Regression, Random Forest, SVM, SARSA\n",
      "Cloud: Amazon Web Services, Google Cloud Platform.\n",
      "EXPERIENCE\n",
      "Sopra Steria\n",
      "Jan 2021 - Dec 2023\n",
      "Data Scientist\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "SKILLS\n",
      "Frameworks: TensorFlow, TernsorFlow Serving, PyTorch, PySpark\n",
      "Models: DBSCAN, BERT, R-CNN, Multi-Linear Regression, Polynomial Regression, Random Forest, SVM, SARSA\n",
      "Cloud: Amazon Web Services, Google Cloud Platform.\n",
      "EXPERIENCE\n",
      "Sopra Steria\n",
      "Jan 2021 - Dec 2023\n",
      "Data Scientist\n",
      "• Gathered historical data on user roles and access patterns. Applied Singular Value Decomposition to reduce\n",
      "the dimensionality of the user-permission matrix. The DBSCAN clustering algorithm was used to analyze\n",
      "user roles, attributes, and group relationships, ensuring accurate and scalable access control.\n",
      "Machine Learning Engineer\n",
      "• Built an NLP model using BERT to analyze detailed descriptions of ServiceNow tickets and automatically\n",
      "classify them into resolution categories. The model was trained on historical ticket data to improve assign-\n",
      "ment accuracy and reduce manual efforts.\n",
      "• Developed a RAG model using Hugging Face Transformers, integrating organizational password policies to\n",
      "deliver targeted security recommendations. Enhanced policy compliance through personalized guidance\n",
      "supported by company-speciﬁc documentation.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "Object Detection on Google’s Open Images Dataset:\n",
      "• Using the distributed computing capabilities of PySpark to preprocess Google’s Open Images Dataset (1M+\n",
      "images) and implemented R-CNN and SSD object detection models using PyTorch on GCP’s distributed in-\n",
      "frastructure.\n",
      "Game of Tigers and Goats:\n",
      "• Developed and implemented a game that features two players (Goat and Tiger). Designed and trained SARSA\n",
      "reinforcement learning agents to optimize player strategies, improving model performance through iterative\n",
      "game simulations.\n",
      "Parkinson’s Disease Regression Analysis\n",
      "• Statistical tests (ANOVA, F-Test) and feature selection techniques were performed to develop regression\n",
      "models to predict Total UPDRS scores in Parkinson’s patients, utilizing voice-related features. Built and op-\n",
      "timized multiple models, including Multi-Linear and Polynomial Regression, to improve prediction accuracy.\n",
      "Online Shoppers Purchasing Intention\n",
      "• Built predictive models using classiﬁers like Random Forest and SVM to analyze online shopper behavior and\n",
      "purchase intentions, addressing class imbalance through under-sampling and over-sampling techniques.\n",
      "EDUCATION\n",
      "Boston University\n",
      "Expected May 2025\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import OllamaEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "import chromadb\n",
    "from langchain_cohere import CohereRerank\n",
    "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
    "import os\n",
    "import cohere\n",
    "\n",
    "cohere_api_key = os.getenv(\"COHERE_API_KEY\")\n",
    "cohere_client = cohere.ClientV2(cohere_api_key)\n",
    "\n",
    "cohere_reranker = CohereRerank(client=cohere_client, model=\"rerank-english-v3.0\", top_n=3)\n",
    "\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=cohere_reranker,\n",
    "    base_retriever=retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6464fd02-7292-44ab-9a6c-4735fbe97e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.2\", temperature=0.5, max_tokens=3000)\n",
    "qa_chain = RetrievalQA.from_chain_type(llm, retriever=compression_retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "64f4ca8b-17b9-4f7b-91c4-6d8f68d083b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query_1 = \"who does the document discuss about?\"\n",
    "user_query_2 = \"what are their achievements?\"\n",
    "user_query_3 = \"what certifications does mahith have? \"\n",
    "user_query_4 = \"what certifications does maruti have?\"\n",
    "user_query_5 = \"Does maruti have any experience working with AI/ML or Blockchain?\"\n",
    "user_query_7 = \"what are their emails?\"\n",
    "user_query_8 = \"my name is mahith\"\n",
    "user_query_9 = \"my roommate name is ankit\"\n",
    "user_query_10 = \"whats my name ? who's my roommate? \"\n",
    "\n",
    "user_queries = [user_query_1, user_query_2, user_query_3, user_query_4, user_query_5, user_query_7, user_query_8, user_query_9, user_query_10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "35e9891c-ad29-47d0-a469-14ad7764499b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: who does the document discuss about?\n",
      "Answer: [The document discusses various individuals, but primarily focuses on a single person.]\n",
      "\n",
      "Key Points:\n",
      "- The document highlights the author's own experiences and achievements.\n",
      "- It also mentions the author's education background at Boston University (expected May 2025).\n",
      "- There is no specific individual discussed in the main body of the text.\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------\n",
      "Question: what are their achievements?\n",
      "Answer: [Their Achievements]\n",
      "\n",
      "Key Points:\n",
      "- Winner at Harvard Blockchain Conference (HBC ’23)\n",
      "- Winner at ETH Boston ‘23\n",
      "- Winner at Columbia Blockchain Hackathon (LionHack ‘23)\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------\n",
      "Question: what certifications does mahith have? \n",
      "Answer: I don't have information on Mahith's certifications.\n",
      "\n",
      "Key Points:\n",
      "- None\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------\n",
      "Question: what certifications does maruti have?\n",
      "Answer: I don't know.\n",
      "\n",
      "Key Points:\n",
      "- No information about Maruti's certifications is provided in the context.\n",
      "- Saimahith Chigurupati, the individual mentioned in the context, has certifications such as AWS Certified Solutions Architect and Pega Certified Senior System Architect.\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------\n",
      "Question: Does maruti have any experience working with AI/ML or Blockchain?\n",
      "Answer: [Yes, Maruti has relevant experience.]\n",
      "\n",
      "Key Points:\n",
      "- Point 1: Maruti worked as a Machine Learning Engineer at Sopra Steria, where they built NLP models using BERT and RAG.\n",
      "- Point 2: They also applied machine learning algorithms like DBSCAN for access control and clustering user roles and attributes.\n",
      "- Point 3: Additionally, Maruti has experience with cloud platforms (AWS and GCP) and has worked on projects involving data science and engineering.\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------\n",
      "Question: what are their emails?\n",
      "Answer: Maruti Mohit Rayalacheruvu's email address is:\n",
      "\n",
      "rayalacheruvu.m@northeastern.edu\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------\n",
      "Question: my name is mahith\n",
      "Answer: [Hello Mahith, I'm happy to help! However, I don't have any information about you beyond what's provided in your LinkedIn profile.]\n",
      "\n",
      "Key Points:\n",
      "- Point 1: No specific connection or relevance between \"Mahith\" and the provided context.\n",
      "- Point 2: No identifiable details for a personalized response.\n",
      "- Point 3: A general greeting is sufficient.\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------\n",
      "Question: my roommate name is ankit\n",
      "Answer: I don't know.\n",
      "\n",
      "Key Points:\n",
      "- None relevant to the question provided.\n",
      "- No information about a roommate named Ankit is available in the context.\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "TooManyRequestsError",
     "evalue": "status_code: 429, body: {'message': \"You are using a Trial key, which is limited to 10 API calls / minute. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.com/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions\"}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTooManyRequestsError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 14\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m user_query \u001b[38;5;129;01min\u001b[39;00m user_queries:\n\u001b[1;32m      2\u001b[0m   prompt \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m      3\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are an expert assistant with a strong grasp of the subject matter. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease answer the following question succinctly, highlighting the key points. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer the following question: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(user_query)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     13\u001b[0m     )\n\u001b[0;32m---> 14\u001b[0m   response \u001b[38;5;241m=\u001b[39m qa_chain\u001b[38;5;241m.\u001b[39minvoke(prompt)\n\u001b[1;32m     15\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuestion: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muser_query\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAnswer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-----------------------------------------------------------------------------------------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/langchain/chains/base.py:170\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    169\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    171\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/langchain/chains/base.py:160\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[1;32m    159\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 160\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs, run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    163\u001b[0m     )\n\u001b[1;32m    165\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    166\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[1;32m    167\u001b[0m     )\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/langchain/chains/retrieval_qa/base.py:151\u001b[0m, in \u001b[0;36mBaseRetrievalQA._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    147\u001b[0m accepts_run_manager \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_docs)\u001b[38;5;241m.\u001b[39mparameters\n\u001b[1;32m    149\u001b[0m )\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m accepts_run_manager:\n\u001b[0;32m--> 151\u001b[0m     docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_docs(question, run_manager\u001b[38;5;241m=\u001b[39m_run_manager)\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    153\u001b[0m     docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_docs(question)  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/langchain/chains/retrieval_qa/base.py:271\u001b[0m, in \u001b[0;36mRetrievalQA._get_docs\u001b[0;34m(self, question, run_manager)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_docs\u001b[39m(\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    266\u001b[0m     question: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m    268\u001b[0m     run_manager: CallbackManagerForChainRun,\n\u001b[1;32m    269\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[1;32m    270\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get docs.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 271\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretriever\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[1;32m    272\u001b[0m         question, config\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_manager\u001b[38;5;241m.\u001b[39mget_child()}\n\u001b[1;32m    273\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/langchain_core/retrievers.py:259\u001b[0m, in \u001b[0;36mBaseRetriever.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    257\u001b[0m _kwargs \u001b[38;5;241m=\u001b[39m kwargs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expects_other_args \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_arg_supported:\n\u001b[0;32m--> 259\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_relevant_documents(\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28minput\u001b[39m, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs\n\u001b[1;32m    261\u001b[0m     )\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    263\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_relevant_documents(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/langchain/retrievers/contextual_compression.py:48\u001b[0m, in \u001b[0;36mContextualCompressionRetriever._get_relevant_documents\u001b[0;34m(self, query, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_retriever\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[1;32m     45\u001b[0m     query, config\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_manager\u001b[38;5;241m.\u001b[39mget_child()}, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m     46\u001b[0m )\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m docs:\n\u001b[0;32m---> 48\u001b[0m     compressed_docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_compressor\u001b[38;5;241m.\u001b[39mcompress_documents(\n\u001b[1;32m     49\u001b[0m         docs, query, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child()\n\u001b[1;32m     50\u001b[0m     )\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(compressed_docs)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/langchain_cohere/rerank.py:151\u001b[0m, in \u001b[0;36mCohereRerank.compress_documents\u001b[0;34m(self, documents, query, callbacks)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;124;03mCompress documents using Cohere's rerank API.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;124;03m    A sequence of compressed documents.\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    150\u001b[0m compressed \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 151\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrerank(documents, query):\n\u001b[1;32m    152\u001b[0m     doc \u001b[38;5;241m=\u001b[39m documents[res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m    153\u001b[0m     doc_copy \u001b[38;5;241m=\u001b[39m Document(doc\u001b[38;5;241m.\u001b[39mpage_content, metadata\u001b[38;5;241m=\u001b[39mdeepcopy(doc\u001b[38;5;241m.\u001b[39mmetadata))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/langchain_cohere/rerank.py:119\u001b[0m, in \u001b[0;36mCohereRerank.rerank\u001b[0;34m(self, documents, query, rank_fields, model, top_n, max_tokens_per_doc)\u001b[0m\n\u001b[1;32m    117\u001b[0m model \u001b[38;5;241m=\u001b[39m model \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m    118\u001b[0m top_n \u001b[38;5;241m=\u001b[39m top_n \u001b[38;5;28;01mif\u001b[39;00m (top_n \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m top_n \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtop_n\n\u001b[0;32m--> 119\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mrerank(\n\u001b[1;32m    120\u001b[0m     query\u001b[38;5;241m=\u001b[39mquery,\n\u001b[1;32m    121\u001b[0m     documents\u001b[38;5;241m=\u001b[39mdocs,\n\u001b[1;32m    122\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    123\u001b[0m     top_n\u001b[38;5;241m=\u001b[39mtop_n,\n\u001b[1;32m    124\u001b[0m     max_tokens_per_doc\u001b[38;5;241m=\u001b[39mmax_tokens_per_doc,\n\u001b[1;32m    125\u001b[0m )\n\u001b[1;32m    126\u001b[0m result_dicts \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mresults:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/cohere/v2/client.py:1094\u001b[0m, in \u001b[0;36mV2Client.rerank\u001b[0;34m(self, model, query, documents, top_n, return_documents, max_tokens_per_doc, request_options)\u001b[0m\n\u001b[1;32m   1084\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnprocessableEntityError(\n\u001b[1;32m   1085\u001b[0m         typing\u001b[38;5;241m.\u001b[39mcast(\n\u001b[1;32m   1086\u001b[0m             typing\u001b[38;5;241m.\u001b[39mOptional[typing\u001b[38;5;241m.\u001b[39mAny],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1091\u001b[0m         )\n\u001b[1;32m   1092\u001b[0m     )\n\u001b[1;32m   1093\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m429\u001b[39m:\n\u001b[0;32m-> 1094\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m TooManyRequestsError(\n\u001b[1;32m   1095\u001b[0m         typing\u001b[38;5;241m.\u001b[39mcast(\n\u001b[1;32m   1096\u001b[0m             typing\u001b[38;5;241m.\u001b[39mOptional[typing\u001b[38;5;241m.\u001b[39mAny],\n\u001b[1;32m   1097\u001b[0m             construct_type(\n\u001b[1;32m   1098\u001b[0m                 type_\u001b[38;5;241m=\u001b[39mtyping\u001b[38;5;241m.\u001b[39mOptional[typing\u001b[38;5;241m.\u001b[39mAny],  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m                 object_\u001b[38;5;241m=\u001b[39m_response\u001b[38;5;241m.\u001b[39mjson(),\n\u001b[1;32m   1100\u001b[0m             ),\n\u001b[1;32m   1101\u001b[0m         )\n\u001b[1;32m   1102\u001b[0m     )\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m498\u001b[39m:\n\u001b[1;32m   1104\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidTokenError(\n\u001b[1;32m   1105\u001b[0m         typing\u001b[38;5;241m.\u001b[39mcast(\n\u001b[1;32m   1106\u001b[0m             typing\u001b[38;5;241m.\u001b[39mOptional[typing\u001b[38;5;241m.\u001b[39mAny],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1111\u001b[0m         )\n\u001b[1;32m   1112\u001b[0m     )\n",
      "\u001b[0;31mTooManyRequestsError\u001b[0m: status_code: 429, body: {'message': \"You are using a Trial key, which is limited to 10 API calls / minute. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.com/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions\"}"
     ]
    }
   ],
   "source": [
    "for user_query in user_queries:\n",
    "  prompt = (\n",
    "      \"You are an expert assistant with a strong grasp of the subject matter. \"\n",
    "      \"Please answer the following question succinctly, highlighting the key points. \"\n",
    "      f\"Ensure your response is relevant and avoid unnecessary elaboration. \"\n",
    "      \"make sure to utilize\n",
    "      f\"Answer the following question: '{(user_query)}'\"\n",
    "    )\n",
    "  response = qa_chain.invoke(prompt)\n",
    "  print(f\"Question: {user_query}\\nAnswer: {response['result']}\\n\")\n",
    "  print(\"-----------------------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39d62cd-eb75-4662-ba6a-35abebcc744c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
