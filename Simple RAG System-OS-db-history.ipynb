{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68e38f45-6ab2-41db-9bae-8c316796cdd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World!\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello World!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d934145-6c52-4725-8b01-a8c0e8905ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pdf_data:  Maruti Mohit Rayalacheruvu \n",
      "(857) 313-2407 | rayalacheruvu.m@northeastern.edu | https://linkedin.com/in/marutimohitr \n",
      " \n",
      "EDUCATION \n",
      "Master of Science in Information Systems, Northeastern Universityâ€‹\n",
      "December 2024 \n",
      " \n",
      "Bachelor of Engineering in Computer Science, Visvesvaraya Technological Universityâ€‹\n",
      "July 2021 \n",
      " \n",
      "TECHNICAL SKILLS \n",
      "Programming Languages: Python, Java, C#, C,  C++ \n",
      "Data Science & ML: Scikit-learn, Statistical Analysis, Data Visualization (Matplotlib, Seaborn), Classification Models, \n"
     ]
    }
   ],
   "source": [
    "import fitz\n",
    "import glob\n",
    "\n",
    "def load_all_pdfs_in_directory(directory=\"./content/\"):\n",
    "  combined_text = \"\"\n",
    "  pdf_paths = glob.glob(f\"{directory}/*.pdf\")\n",
    "\n",
    "  for file_path in pdf_paths:\n",
    "    with fitz.open(file_path) as pdf:\n",
    "      for page in pdf:\n",
    "        combined_text += page.get_text()\n",
    "\n",
    "  return combined_text\n",
    "\n",
    "pdf_data = load_all_pdfs_in_directory()\n",
    "print(\"Pdf_data: \", pdf_data[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d20ec44-aa0f-427c-8628-4ce6dc1e58e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13088"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pdf_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a0fbd33-9d64-4076-b5d5-ebbee28ce9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents:  15\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1200,\n",
    "    chunk_overlap=300\n",
    ")\n",
    "\n",
    "documents = text_splitter.split_text(pdf_data)\n",
    "print(\"Number of documents: \", len(documents))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fefec4b-53e4-40c0-94b9-c5aaec6ae387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Maruti Mohit Rayalacheruvu \\n(857) 313-2407 | rayalacheruvu.m@northeastern.edu | https://linkedin.com/in/marutimohitr \\n \\nEDUCATION \\nMaster of Science in Information Systems, Northeastern University\\u200b\\nDecember 2024 \\n \\nBachelor of Engineering in Computer Science, Visvesvaraya Technological University\\u200b\\nJuly 2021 \\n \\nTECHNICAL SKILLS \\nProgramming Languages: Python, Java, C#, C,  C++ \\nData Science & ML: Scikit-learn, Statistical Analysis, Data Visualization (Matplotlib, Seaborn), Classification Models, \\nFeature Engineering, Pandas, NumPy, Model Optimization, Jupyter, Predictive Modeling \\nTechnologies: SQL (PostgreSQL), AWS, JavaScript, TypeScript, React, Node.js, Express, MongoDB, Docker, CI/CD \\nFrameworks: Data Structures & Algorithms, Microservices Architecture, .NET Core, Git, Linux, Unit Testing, Postman \\n \\nWORK EXPERIENCE \\nAssociate Software Engineer, Conga\\u200b\\n\\u200b\\nJuly 2021 â€“ August 2022 \\nâ—\\u200b Architected cloud-native microservices with C#, .NET Core, and AWS to process documents across cloud storage \\nproviders, implementing data pipelines for real-time analytics and processing \\nâ—\\u200b Optimized event-driven communication by configuring Amazon SQS and SNS and monitoring Grafana dashboards,'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08ce4dc0-a9f9-40a8-90ed-b0df8da18078",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=\"llama3.2\")\n",
    "\n",
    "embedded_documents = embeddings.embed_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7f4fcfd-7dc7-45b1-a8b8-fdc0c4d86b9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding for the first document\n",
      "Component 1: 0.008276723\n",
      "Component 2: -0.00096380425\n",
      "Component 3: -0.01307932\n",
      "Component 4: 0.008557427\n",
      "Component 5: -0.006538015\n",
      "Component 6: 0.013165651\n"
     ]
    }
   ],
   "source": [
    "print(\"Embedding for the first document\")\n",
    "for i, value in enumerate(embedded_documents[0]):\n",
    "  print(f\"Component {i+1}: {value}\")\n",
    "  if i >= 5:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5a5a6ce-4017-4746-92ae-900089a8b11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "# 4ï¸âƒ£ Store Embeddings in ChromaDB\n",
    "chroma_db = Chroma.from_texts(texts=documents, embedding=embeddings, persist_directory=\"chroma_db\")\n",
    "\n",
    "# 5ï¸âƒ£ Load ChromaDB Index\n",
    "vectorstore = Chroma(persist_directory=\"chroma_db\", embedding_function=embeddings)\n",
    "\n",
    "# 6ï¸âƒ£ Create User Chat History Vectorstore\n",
    "history_db = Chroma(persist_directory=\"history_db\", embedding_function=embeddings)\n",
    "\n",
    "# 7ï¸âƒ£ Define Retriever\n",
    "top_k = 6  # Number of top results to retrieve\n",
    "doc_retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": top_k})\n",
    "history_retriever = history_db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": top_k})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2dd34ab6-53ca-4235-a2ff-a564d1e8365e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents indexed: 15\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of documents indexed: {len(documents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2b52e4da-9102-4d47-b8b2-c954ff9738a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f289554b-22dd-4ffc-8e8b-baf9ff825d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print(docs):\n",
    "  print(\n",
    "      f\"\\n{'-' * 100}\\n\".join(\n",
    "          [f\"Document {i+1}:\\n\\n\"+ d.page_content for i,d in enumerate(docs)]\n",
    "      )\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "178b72f2-e0d7-4d3a-b045-f3d1fed556e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COHERE_API_KEY: fqbB6WXKvozEcRdd0nYShpVATojBVadM4EmCUs2G\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"COHERE_API_KEY\"] = \"fqbB6WXKvozEcRdd0nYShpVATojBVadM4EmCUs2G\"  # Set the API key\n",
    "print(f\"COHERE_API_KEY: {os.getenv('COHERE_API_KEY')}\")  # Make sure the key is not None or empty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76631f4c-9f17-40e8-b1be-f1c33d646c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OllamaEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "import chromadb\n",
    "from langchain_cohere import CohereRerank\n",
    "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
    "import os\n",
    "import cohere\n",
    "\n",
    "cohere_api_key = os.getenv(\"COHERE_API_KEY\")\n",
    "cohere_client = cohere.ClientV2(cohere_api_key)\n",
    "\n",
    "cohere_reranker = CohereRerank(client=cohere_client, model=\"rerank-english-v3.0\", top_n=3)\n",
    "\n",
    "# compression_retriever = ContextualCompressionRetriever(\n",
    "#     base_compressor=cohere_reranker,\n",
    "#     base_retriever=retriever\n",
    "# )\n",
    "\n",
    "doc_compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=cohere_reranker,\n",
    "    base_retriever=doc_retriever\n",
    ")\n",
    "history_compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=cohere_reranker,\n",
    "    base_retriever=history_retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6464fd02-7292-44ab-9a6c-4735fbe97e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.2\", temperature=0.5, max_tokens=3000)\n",
    "# qa_chain = RetrievalQA.from_chain_type(llm, retriever=compression_retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64f4ca8b-17b9-4f7b-91c4-6d8f68d083b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_query_1 = \"who does the document discuss about?\"\n",
    "# user_query_2 = \"what are their achievements?\"\n",
    "# user_query_3 = \"what certifications does mahith have? \"\n",
    "# user_query_4 = \"what certifications does maruti have?\"\n",
    "# user_query_5 = \"Does maruti have any experience working with AI/ML or Blockchain?\"\n",
    "# user_query_7 = \"what are their emails?\"\n",
    "# user_query_8 = \"my name is mahith\"\n",
    "# user_query_9 = \"my roommate name is ankit\"\n",
    "# user_query_10 = \"whats my name ? who's my roommate? \"\n",
    "\n",
    "# user_queries = [user_query_1, user_query_2, user_query_3, user_query_4, user_query_5, user_query_7, user_query_8, user_query_9, user_query_10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35e9891c-ad29-47d0-a469-14ad7764499b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Ask a question (or type 'exit' to quit):  hello\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 6 is greater than number of elements in index 5, updating n_results = 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Unfortunately, I don't have enough context to provide a meaningful response to your greeting. The chat history is currently empty, and there are no documents or other knowledge sources available to draw upon. Could you please provide more context or ask a specific question? I'll do my best to assist you.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Ask a question (or type 'exit' to quit):  what does the documents discuss about?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: The document knowledge discusses various topics:\n",
      "\n",
      "1. Object Detection on Googleâ€™s Open Images Dataset: This section talks about using distributed computing capabilities to preprocess a large dataset and implementing object detection models.\n",
      "2. Game of Tigers and Goats: It discusses developing and implementing a game that features two players (Goat and Tiger) and training SARSA reinforcement learning agents to optimize player strategies.\n",
      "3. Parkinsonâ€™s Disease Regression Analysis: This section covers statistical tests, feature selection techniques, and regression models for predicting Total UPDRS scores in Parkinson's patients using voice-related features.\n",
      "\n",
      "These topics seem to be unrelated to each other, as they cover different domains such as computer vision, game development, and medical research.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Ask a question (or type 'exit' to quit):  who does these documents discuss about?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: The documents appear to be a professional resume or biography of Maruti Mohit Rayalacheruvu. They discuss his education, technical skills, work experience, and certifications.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Ask a question (or type 'exit' to quit):  my name is mahith and my roommmate name is ankit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: I don't have any information about a person named Mahith having a roommate named Ankit in our chat history or document knowledge. Could you please provide more context or clarify who Mahith is? I'll do my best to help.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Ask a question (or type 'exit' to quit):  whats my name\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: I don't have any information about your name in either the document knowledge or chat history. Could you please provide more context or clarify who you are asking about? I'll do my best to help based on the available information.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ðŸ”Ÿ Interactive User Query Loop\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m----> 3\u001b[0m     user_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsk a question (or type \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexit\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to quit): \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m user_query\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexit\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGoodbye!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py:1262\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1260\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_request(\n\u001b[1;32m   1263\u001b[0m     \u001b[38;5;28mstr\u001b[39m(prompt),\n\u001b[1;32m   1264\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_ident[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   1265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_parent(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1266\u001b[0m     password\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1267\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py:1305\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1303\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1304\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1306\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1307\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "# ðŸ”Ÿ Interactive User Query Loop\n",
    "while True:\n",
    "    user_query = input(\"Ask a question (or type 'exit' to quit): \")\n",
    "    if user_query.lower() == 'exit':\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "    \n",
    "    # Retrieve relevant information from document and history databases\n",
    "    doc_results = doc_compression_retriever.get_relevant_documents(user_query)\n",
    "    history_results = history_compression_retriever.get_relevant_documents(user_query)\n",
    "    \n",
    "    doc_context = \"\\n\".join([doc.page_content for doc in doc_results])\n",
    "    history_context = \"\\n\".join([hist.page_content for hist in history_results])\n",
    "    \n",
    "    prompt = (\n",
    "        \"You are an expert assistant with access to two sources of knowledge: \"\n",
    "        \"document knowledge and chat history. \"\n",
    "        \"Use document knowledge to answer factual questions and chat history to recall user-provided context.\\n\\n\"\n",
    "        \"### Document Knowledge:\\n\"\n",
    "        f\"{doc_context}\\n\\n\"\n",
    "        \"### Chat History:\\n\"\n",
    "        f\"{history_context}\\n\\n\"\n",
    "        \"Answer the user's query using the most relevant information from the provided sources. \"\n",
    "        f\"If relevant information is missing, state that clearly.\\n\\nUser Query: {user_query}\"\n",
    "    )\n",
    "    \n",
    "    response = llm.invoke(prompt)\n",
    "    response_text = response.content if hasattr(response, 'content') else str(response)\n",
    "    print(f\"Answer: {response_text}\\n\")\n",
    "    \n",
    "    # Store user query and response in history_db\n",
    "    history_db.add_texts(user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39d62cd-eb75-4662-ba6a-35abebcc744c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
